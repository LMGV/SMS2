for (i in 1:8){
for (j in 1:8){
segments(eight[i,1],eight[i,2 ],eight[j,1 ],eight[j,2],lwd=2,"black")
}
}
# Plot Distances
for (i in 1:8){
for (j in 1:8){
if (i!=j){
points((eight[i,1]+eight[j,1])/2, (eight[i,2]+eight[j,2])/2, pch=22, cex=3, bg="white")
text((eight[i,1]+eight[j,1])/2, (eight[i,2]+eight[j,2])/2 ,
dist_eight[i,j],col="red3", cex = 0.8)
}
}
}
# Plot Nodes
points(eight, pch=21, cex=3, bg="white")
text(eight[,1],eight[,2],as.character(1:8),col="blue3",cex=1)
# clear cache and close windows
graphics.off()
rm(list=ls(all=TRUE))
# define eight points, compute distance matrix
eight        = cbind(c(-3,-2,-2,-2,1,1,2,4),c(0,4,-1,-2,4,2,-4,-3))
eight        = eight[c(8,7,3,1,4,2,6,5),]
dist_eight   = (as.matrix(dist(eight, method = "euclidian")))^2
comb = c(1,2,5,3,4,6,8,7)
dev.new()
# plot eight points using average linkage
par(mfrow = c(1, 1),cex=1)
plot(eight, pch=16, xlab="price conciousness",ylab="brand loyalty",main="8 points",
xlim=c(-4.1,4.1),ylim=c(-4.1,4.1))
# Plot Lines
for (i in 2:length(comb)) {
segments(eight[comb[i-1],1],eight[comb[i-1],2 ],eight[comb[i],1 ],eight[comb[i],2],lwd=2,"black")
}
# Plot Distances
for (j in 2:8) {
points((eight[comb[j-1],1]+eight[comb[j],1])/2, (eight[comb[j-1],2]+eight[comb[j],2])/2, pch=22, cex=3, bg="white")
text((eight[comb[j-1],1]+eight[comb[j],1])/2, (eight[comb[j-1],2]+eight[comb[j],2])/2 ,
dist_eight[comb[j-1],comb[j]],col="red3", cex = 0.8)
}
# Plot Nodes
points(eight, pch=21, cex=3, bg="white")
text(eight[,1],eight[,2],as.character(1:8),col="blue3",cex=1)
# close windows, clear variables
rm(list = ls(all = TRUE))
graphics.off()
install.packages("kernlab")
library(kernlab)
install.packages("ellipse")
library(ellipse)
################################################################################
########################## manipulate subroutine specc #########################
#################### to return eigenvalues and eigenvectors ####################
################################################################################
setGeneric("specc",function(x, ...) standardGeneric("specc"))
setMethod("specc", signature(x = "formula"),
function(x, data = NULL, na.action = na.omit, ...)
{
mt <- terms(x, data = data)
if(attr(mt, "response") > 0) stop("response not allowed in formula")
attr(mt, "intercept") <- 0
cl <- match.call()
mf <- match.call(expand.dots = FALSE)
mf$formula <- mf$x
mf$... <- NULL
mf[[1]] <- as.name("model.frame")
mf <- eval(mf, parent.frame())
na.act <- attr(mf, "na.action")
x <- model.matrix(mt, mf)
res <- specc(x, ...)
cl[[1]] <- as.name("specc")
if(!is.null(na.act))
n.action(res) <- na.action
return(res)
})
setMethod("specc",signature(x="matrix"),function(x, centers, kernel = "rbfdot", kpar = "automatic", nystrom.red = FALSE, nystrom.sample = dim(x)[1]/6, iterations = 200, mod.sample =  0.75, na.action = na.omit, ...)
{
x <- na.action(x)
rown <- rownames(x)
x <- as.matrix(x)
m <- nrow(x)
if (missing(centers))
stop("centers must be a number or a matrix")
if (length(centers) == 1) {
nc <-  centers
if (m < centers)
stop("more cluster centers than data points.")
}
else
nc <- dim(centers)[2]
if(is.character(kpar)) {
kpar <- match.arg(kpar,c("automatic","local"))
if(kpar == "automatic")
{
if (nystrom.red == TRUE)
sam <- sample(1:m, floor(mod.sample*nystrom.sample))
else
sam <- sample(1:m, floor(mod.sample*m))
sx <- unique(x[sam,])
ns <- dim(sx)[1]
dota <- rowSums(sx*sx)/2
ktmp <- crossprod(t(sx))
for (i in 1:ns)
ktmp[i,]<- 2*(-ktmp[i,] + dota + rep(dota[i], ns))
## fix numerical prob.
ktmp[ktmp<0] <- 0
ktmp <- sqrt(ktmp)
kmax <- max(ktmp)
kmin <- min(ktmp + diag(rep(Inf,dim(ktmp)[1])))
kmea <- mean(ktmp)
lsmin <- log2(kmin)
lsmax <- log2(kmax)
midmax <- min(c(2*kmea, kmax))
midmin <- max(c(kmea/2,kmin))
rtmp <- c(seq(midmin,0.9*kmea,0.05*kmea), seq(kmea,midmax,0.08*kmea))
if ((lsmax - (Re(log2(midmax))+0.5)) < 0.5) step <- (lsmax - (Re(log2(midmax))+0.5))
else step <- 0.5
if (((Re(log2(midmin))-0.5)-lsmin) < 0.5 ) stepm <-  ((Re(log2(midmin))-0.5) - lsmin)
else stepm <- 0.5
tmpsig <- c(2^(seq(lsmin,(Re(log2(midmin))-0.5), stepm)), rtmp, 2^(seq(Re(log2(midmax))+0.5, lsmax,step)))
diss <- matrix(rep(Inf,length(tmpsig)*nc),ncol=nc)
for (i in 1:length(tmpsig)){
ka <- exp((-(ktmp^2))/(2*(tmpsig[i]^2)))
diag(ka) <- 0
d <- 1/sqrt(rowSums(ka))
if(!any(d==Inf) && !any(is.na(d))&& (max(d)[1]-min(d)[1] < 10^4))
{
l <- d * ka %*% diag(d)
xi <- eigen(l,symmetric=TRUE)$vectors[,1:nc]
yi <- xi/sqrt(rowSums(xi^2))
res <- kmeans(yi, centers, iterations)
diss[i,] <- res$withinss
}
}
ms <- which.min(rowSums(diss))
kernel <- rbfdot((tmpsig[ms]^(-2))/2)
## Compute Affinity Matrix
if (nystrom.red == FALSE)
km <- kernelMatrix(kernel, x)
}
if (kpar=="local")
{
if (nystrom.red == TRUE)
stop ("Local Scaling not supported for nystrom reduction.")
s <- rep(0,m)
dota <- rowSums(x*x)/2
dis <- crossprod(t(x))
for (i in 1:m)
dis[i,]<- 2*(-dis[i,] + dota + rep(dota[i],m))
## fix numerical prob.
dis[dis < 0] <- 0
for (i in 1:m)
s[i] <- median(sort(sqrt(dis[i,]))[1:5])
## Compute Affinity Matrix
km <- exp(-dis / s%*%t(s))
kernel <- "Localy scaled RBF kernel"
}
}
else
{
if(!is(kernel,"kernel"))
{
if(is(kernel,"function")) kernel <- deparse(substitute(kernel))
kernel <- do.call(kernel, kpar)
}
if(!is(kernel,"kernel")) stop("kernel must inherit from class `kernel'")
## Compute Affinity Matrix
if (nystrom.red == FALSE)
km <- kernelMatrix(kernel, x)
}
if (nystrom.red == TRUE){
n <- floor(nystrom.sample)
ind <- sample(1:m, m)
x <- x[ind,]
tmps <- sort(ind, index.return = TRUE)
reind <- tmps$ix
A <- kernelMatrix(kernel, x[1:n,])
B <- kernelMatrix(kernel, x[-(1:n),], x[1:n,])
d1 <- colSums(rbind(A,B))
d2 <- rowSums(B) + drop(matrix(colSums(B),1) %*% .ginv(A)%*%t(B))
dhat <- sqrt(1/c(d1,d2))
A <- A * (dhat[1:n] %*% t(dhat[1:n]))
B <- B * (dhat[(n+1):m] %*% t(dhat[1:n]))
Asi <- .sqrtm(.ginv(A))
Q <- A + Asi %*% crossprod(B) %*% Asi
tmpres <- svd(Q)
U <- tmpres$u
L <- tmpres$d
V <- rbind(A,B) %*% Asi %*% U %*% .ginv(sqrt(diag(L)))
yi <- matrix(0,m,nc)
## for(i in 2:(nc +1))
##   yi[,i-1] <- V[,i]/V[,1]
for(i in 1:nc) ## specc
yi[,i] <- V[,i]/sqrt(sum(V[,i]^2))
res <- kmeans(yi[reind,], centers, iterations)
}
else{
if(is(kernel)[1] == "rbfkernel")
diag(km) <- 0
d <- 1/sqrt(rowSums(km))
l <- d * km %*% diag(d)
xu <- eigen(l)$values[1:nc]
xi <- eigen(l)$vectors[,1:nc]
xxu <- eigen(l)$values
xxi <- eigen(l)$vectors
yi <- xi/sqrt(rowSums(xi^2))
res <- kmeans(yi, centers, iterations)
}
cent <- matrix(unlist(lapply(1:nc,ll<- function(l){colMeans(x[which(res$cluster==l),])})),ncol=dim(x)[2], byrow=TRUE)
withss <- unlist(lapply(1:nc,ll<- function(l){sum((x[which(res$cluster==l),] - cent[l,])^2)}))
names(res$cluster) <- rown
return(new("specc", .Data=list(data=res$cluster,evalues=xxu, evectors=xxi), size = res$size, centers=cent, withinss=withss, kernelf= kernel))
})
###########################################################################
############################## main computation ###########################
###########################################################################
set.seed(1)
# define eight points
eight  = cbind(c(-3,-2,-2,-2,1,1,2,4),c(0,4,-1,-2,4,2,-4,-3))
eight  = eight[c(8,7,3,1,4,2,6,5),]
sc      = specc(eight, centers=2)
centers = attr(sc, "centers") # center coordinates
size    = attr(sc, "size")    # size of clusters
datacl  = sc$data             # clusters
evalues = sc$evalues          # eigenvalues
evectors= sc$evectors         # eigenvectors
xtable(as.matrix(evalues))
xtable(evectors)
plot(eight,type="n",xlab="price conciousness",ylab="brand loyalty",xlim=c(-4,4),main="8 points")
points(eight, pch=21, cex=2.7, bg="white")
text(eight,as.character(1:8),col="red3",xlab="first coordinate", ylab="second coordinate", main="8 points",cex=1)
lines(ellipse(0.6,centre=centers[2,],scale=c(1.2,2)),col="red3",lwd=2)
lines(ellipse(0.6,centre=centers[1,],scale=c(.7,.4)),col="blue3",lwd=2)
# clear cache and close windows
graphics.off()
rm(list=ls(all=TRUE))
# install.packages("car")
library(car)
# define eight points
eight  = cbind(c(-3,-2,-2,-2,1,1,2,4),c(0,4,-1,-2,4,2,-4,-3))
eight  = eight[c(8,7,3,1,4,2,6,5),]
w      = hclust(dist(eight,method="euclidean")^2,method="centroid")
groups = cutree(w, k=2)
merg   = cbind(eight, as.matrix(groups))
merg   = merg[sort.list(merg[,3]),]
merg1  = merg[which(merg[,3]==1),1:2]
merg2  = merg[which(merg[,3]==2),1:2]
m1     = apply(merg1,2,mean)
m2     = apply(merg2,2,mean)
dev.new()
# plot eight points using centroid linkage
par(mfrow = c(1, 2))
plot(eight,type="n", xlab="price conciousness",ylab="brand loyalty",main="8 points - centroid linkage", xlim=c(-4,4))
dataEllipse(x = c(merg1[,1]), y = c(merg1[,2]), center.pch = 1, col = "red",
plot.points = F, add = T,levels = 0.7)
dataEllipse(x = merg2[,1], y = merg2[,2], center.pch = 1, col = "blue",
plot.points = F, add = T,levels = 0.7)
segments(m2[1],m2[2],eight[3,1],eight[3,2],lwd=2)
segments(m2[1],m2[2],eight[4,1],eight[4,2],lwd=2)
segments(m2[1],m2[2],eight[5,1],eight[5,2],lwd=2)
segments(m2[1],m2[2],eight[6,1],eight[6,2],lwd=2)
segments(m2[1],m2[2],eight[7,1],eight[7,2],lwd=2)
segments(m2[1],m2[2],eight[8,1],eight[8,2],lwd=2)
segments(m1[1],m1[2],eight[1,1],eight[1,2],lwd=2)
segments(m1[1],m1[2],eight[2,1],eight[2,2],lwd=2)
segments(m1[1],m1[2],m2[1],m2[2],lwd=2)
points(eight, pch=21, cex=2.6, bg="white")
text(eight,as.character(1:8),col="red3",cex=1)
plot(hclust(dist(eight,method="euclidean")^2,method="centroid"),ylab="squared Euclidean distance",sub="",xlab="",main="centroid linkage dendrogram")
# clear variables and close windows
rm(list=ls(all=TRUE))
graphics.off()
#install.packages("MASS")
library(MASS)
cereal = matrix(c(UScereal$calories, UScereal$protein ,UScereal$fat,
UScereal$sugars), nrow = length(UScereal$calories), ncol = 4)
rownames(cereal) = paste("C",1:65, sep="")
colnames(cereal) = c("calories", "protein", "fat", "sugars")
sc_cereal = scale(cereal)
D         = dist(sc_cereal, method="euclidean")
hc        = hclust(D,"ward")
plot(as.dendrogram(hc),xlab="",sub="",ylab="Euclidean distance",
main = "Ward dendrogram for US cereal data")
pr             = prcomp(sc_cereal)
prx            = t(t(pr$x[,1:2])*(sign(pr$x[1,1:2])))
cut            = cutree(hc, h = 15)
merg           = matrix(c(prx, as.matrix(cut)), nrow = 65, ncol = 3)
rownames(merg) = rownames(prx)
merg           = merg[sort.list(merg[,3]),]
merg1          = merg[1:17,1:2]
merg2          = merg[18:41,1:2]
merg3          = merg[42:65,1:2]
dev.new()
plot(prx,type="n",xlab="first PC",ylab="second PC",
main="65 US cereals, cut height 15")
text(merg1[,1],merg1[,2],rownames(merg1),cex=1.2, col="red3")
text(merg2[,1],merg2[,2],rownames(merg2),cex=1.2, col="blue3")
text(merg3[,1],merg3[,2],rownames(merg3),cex=1.2, col="black")
# clear cache and close windows
rm(list=ls(all=TRUE))
graphics.off()
setwd("Users/allapetuhina/Documents/LvB_duties/SMS2_Q_later_delete/SMSclushealth05/")        # please change your working directory
ushealth05 = read.csv("ushealth05.csv",sep=",",header=T) # load ushealth data
ush        = ushealth05[order(ushealth05[,20]),] # order data
ushreg     = as.numeric(ush[,20])                # def. region
ushreg[ushreg==1] = 0;ushreg[ushreg==2] = 1;ushreg[ushreg==0] = 2;ushreg[ushreg==3] = 6
ushreg[ushreg==4] = 3;ushreg[ushreg==5] = 4;ushreg[ushreg==6] = 5
lab            = paste(ush[,22],ushreg)
row.names(ush) = lab
D              = dist(ush[,3:12],method="euclidean", p=2) # pairwise "euclidean" distance matrix
# using only the relevant health related causes of death
hc             = hclust(D,"ward") # perform cluster analysis using "ward" agglomeration algorithm
cl             = cutree(hc,4)     # select only 4 clusters
# plot dendrogram
opar       = par(mar=c(2, 5, 4, 2) +  5.5,cex=0.6,cex.axis=1.2,cex.main=2,cex.lab=1.4)
plot(as.dendrogram(hc),horiz=T#,main="Ward dendrogram for US health"
,xlab="",sub="",cex=1.1,ylab="Euclidean distance")
title("Ward dendrogram for US health",line=-0.5)
# perform principal component analysis to show clusters on a 2D set
pr         = prcomp(ush[,3:12])
prx        = t(t(pr$x[,1:2])*(sign(pr$x[1,1:2])))
cl2        = as.numeric(cl) # resetting colours
cl2[cl==1] = 2
cl2[cl==4] = 1
cl2[cl==2] = 3
cl2[cl==3] = 4
# plot principal components and the clusters by colour and size
par(opar)
plot(prx[,1],prx[,2],type="n",main="US health",ylab="PC2",xlab="PC1")
text(prx[,1],prx[,2],lab,xpd=NA,col=as.numeric(cl2),cex=1+0.2*as.numeric(cl2))#+1)
mu.table = rbind(apply(ush[which(cl==1),3:12],2,mean),apply(ush[which(cl==2),3:12],2,mean),apply(ush[which(cl==3),3:12],2,mean),apply(ush[which(cl==4),3:12],2,mean))
rm(list=ls(all=TRUE))
graphics.off()
setwd("Users/allapetuhina/Documents/LvB_duties/SMS2_Q_later_delete/SMSclushealth05/")        # please change your working directory
setwd("Users/allapetuhina/Documents/LvB_duties/SMS2_Q_later_delete/SMSclushealth05")        # please change your working directory
setwd("Users/allapetuhina/Documents/LvB_duties/SMS2_Q_later_delete/SMSclushealth05/")        # please change your working directory
setwd("~/Documents/LvB_duties/SMS2_Q_later_delete/SMSdisthealth05")
# clear cache and close windows
rm(list=ls(all=TRUE))
graphics.off()
setwd("Users/allapetuhina/Documents/LvB_duties/SMS2_Q_later_delete/SMSclushealth05")        # please change your working directory
ushealth05 = read.csv("ushealth05.csv",sep=",",header=T) # load ushealth data
ush        = ushealth05[order(ushealth05[,20]),] # order data
ushreg     = as.numeric(ush[,20])                # def. region
ushreg[ushreg==1] = 0;ushreg[ushreg==2] = 1;ushreg[ushreg==0] = 2;ushreg[ushreg==3] = 6
ushreg[ushreg==4] = 3;ushreg[ushreg==5] = 4;ushreg[ushreg==6] = 5
lab            = paste(ush[,22],ushreg)
row.names(ush) = lab
D              = dist(ush[,3:12],method="euclidean", p=2) # pairwise "euclidean" distance matrix
# using only the relevant health related causes of death
hc             = hclust(D,"ward") # perform cluster analysis using "ward" agglomeration algorithm
cl             = cutree(hc,4)     # select only 4 clusters
# plot dendrogram
opar       = par(mar=c(2, 5, 4, 2) +  5.5,cex=0.6,cex.axis=1.2,cex.main=2,cex.lab=1.4)
plot(as.dendrogram(hc),horiz=T#,main="Ward dendrogram for US health"
,xlab="",sub="",cex=1.1,ylab="Euclidean distance")
title("Ward dendrogram for US health",line=-0.5)
# perform principal component analysis to show clusters on a 2D set
pr         = prcomp(ush[,3:12])
prx        = t(t(pr$x[,1:2])*(sign(pr$x[1,1:2])))
cl2        = as.numeric(cl) # resetting colours
cl2[cl==1] = 2
cl2[cl==4] = 1
cl2[cl==2] = 3
cl2[cl==3] = 4
# plot principal components and the clusters by colour and size
par(opar)
plot(prx[,1],prx[,2],type="n",main="US health",ylab="PC2",xlab="PC1")
text(prx[,1],prx[,2],lab,xpd=NA,col=as.numeric(cl2),cex=1+0.2*as.numeric(cl2))#+1)
mu.table = rbind(apply(ush[which(cl==1),3:12],2,mean),apply(ush[which(cl==2),3:12],2,mean),apply(ush[which(cl==3),3:12],2,mean),apply(ush[which(cl==4),3:12],2,mean))
setwd("~/Documents/LvB_duties/SMS2_Q_later_delete/SMScluskmhealth")
graphics.off()
rm(list=ls(all=T))
# setwd("C:/...")
# install required packages
# install.packages("MASS")
library(MASS)
# set pseudo random numbers for algorithm starting value
set.seed(99)
ushealth = read.csv("ushealth05.csv",sep=",",header=T) # load data
results  = kmeans(ushealth[,3:12],4, algorithm="Lloyd") # k-means algorithm
PC       = prcomp(ushealth[3:12])$x[,1:2] # PCA
# first 2 PCs with clusters in 4 colours
plot(PC,type="n",main="US health data")
cl         = as.numeric(results$cluster)
col        = cl
col[cl==3] = 2
col[cl==2] = 3
text(PC[,1],PC[,2],ushealth$ANSI,col=col)
setwd("~/Documents/LvB_duties/SMS2_Q_later_delete/SMSdisthealth05")
# clear cache and close windows
rm(list=ls(all=TRUE))
graphics.off()
#setwd("C:/...")        # please change your working directory
ushealth05        = read.csv("ushealth05.csv",sep=",",header=T) # load ushealth data
ush               = ushealth05[order(ushealth05[,20]),] # order data
ushreg            = as.numeric(ush[,20])                # def. regrion
lab               = paste(ush[,22],ushreg)
row.names(ush)    = lab
ush        = ush[c(which(ush$ANSI==c("ME")),which(ush$ANSI==c("NH")),which(ush$ANSI==c("NY"))),]     # use only Maine, New Hampshire, New York
ush        = ush[,3:12] # for the disease related death causes
# Euclidean distance
dist.eu    = dist(ush,method="euclidean",p=2,diag=T)
dist.eu
# Manhattan distance
dist.ma    = dist(ush,method="manhattan",p=2,diag=T)
dist.ma
# Maximum distance
dist.mi    = dist(ush,method="maximum",p=2,diag=T)
dist.mi
rm(list=ls())
graphics.off()
# install.packages("mvtnorm)
library(mvtnorm)
n      = 100
rho    = 0.9
mean_x = c(0,0)
mean_y = c(4,0)
sigma  = matrix(c(1,rho,rho,1), nrow = 2, ncol = 2)
x      = rmvnorm(n=n, mean = mean_x, sigma = sigma)
y      = rmvnorm(n=n, mean = mean_y, sigma = sigma)
xy     = rbind(x,y) # defined for computing xlim and ylim
plot(x, col='red', pch = 19, ylim = c(round(min(xy[,2]))-1,round(max(xy[,2]))+1),
xlim = c(round(min(xy[,1]))-1,round(max(xy[,1]))+1),
xlab = 'x1, y1', ylab = 'x2, y2')
points(y,col = 'blue', pch = 19)
rm(list=ls())
graphics.off()
install.packages("mvtnorm)
library(mvtnorm)
n      = 100
rho    = 0.9
mean_x = c(0,0)
mean_y = c(4,0)
sigma  = matrix(c(1,rho,rho,1), nrow = 2, ncol = 2)
x      = rmvnorm(n=n, mean = mean_x, sigma = sigma)
y      = rmvnorm(n=n, mean = mean_y, sigma = sigma)
xy     = rbind(x,y) # defined for computing xlim and ylim
plot(x, col='red', pch = 19, ylim = c(round(min(xy[,2]))-1,round(max(xy[,2]))+1),
xlim = c(round(min(xy[,1]))-1,round(max(xy[,1]))+1),
xlab = 'x1, y1', ylab = 'x2, y2')
points(y,col = 'blue', pch = 19)
install.packages("mvtnorm)
rm(list=ls())
graphics.off()
install.packages("mvtnorm)
library(mvtnorm)
n      = 100
rho    = 0.9
mean_x = c(0,0)
mean_y = c(4,0)
sigma  = matrix(c(1,rho,rho,1), nrow = 2, ncol = 2)
x      = rmvnorm(n=n, mean = mean_x, sigma = sigma)
y      = rmvnorm(n=n, mean = mean_y, sigma = sigma)
xy     = rbind(x,y) # defined for computing xlim and ylim
plot(x, col='red', pch = 19, ylim = c(round(min(xy[,2]))-1,round(max(xy[,2]))+1),
xlim = c(round(min(xy[,1]))-1,round(max(xy[,1]))+1),
xlab = 'x1, y1', ylab = 'x2, y2')
points(y,col = 'blue', pch = 19)
rm(list=ls())
graphics.off()
install.packages(mvtnorm)
library(mvtnorm)
n      = 100
rho    = 0.9
mean_x = c(0,0)
mean_y = c(4,0)
sigma  = matrix(c(1,rho,rho,1), nrow = 2, ncol = 2)
x      = rmvnorm(n=n, mean = mean_x, sigma = sigma)
y      = rmvnorm(n=n, mean = mean_y, sigma = sigma)
xy     = rbind(x,y) # defined for computing xlim and ylim
plot(x, col='red', pch = 19, ylim = c(round(min(xy[,2]))-1,round(max(xy[,2]))+1),
xlim = c(round(min(xy[,1]))-1,round(max(xy[,1]))+1),
xlab = 'x1, y1', ylab = 'x2, y2')
points(y,col = 'blue', pch = 19)
rm(list=ls())
graphics.off()
install.packages(mvtnorm)
library(mvtnorm)
n      = 100
rho    = 0.9
mean_x = c(0,0)
mean_y = c(4,0)
sigma  = matrix(c(1,rho,rho,1), nrow = 2, ncol = 2)
x      = rmvnorm(n=n, mean = mean_x, sigma = sigma)
y      = rmvnorm(n=n, mean = mean_y, sigma = sigma)
xy     = rbind(x,y) # defined for computing xlim and ylim
plot(x, col='red', pch = 19, ylim = c(round(min(xy[,2]))-1,round(max(xy[,2]))+1),
xlim = c(round(min(xy[,1]))-1,round(max(xy[,1]))+1),
xlab = 'x1, y1', ylab = 'x2, y2')
points(y,col = 'blue', pch = 19)
rm(list=ls())
graphics.off()
install.packages(mvtnorm)
library(mvtnorm)
rm(list=ls())
graphics.off()
install.packages("mvtnorm")
library(mvtnorm)
n      = 100
rho    = 0.9
mean_x = c(0,0)
mean_y = c(4,0)
sigma  = matrix(c(1,rho,rho,1), nrow = 2, ncol = 2)
x      = rmvnorm(n=n, mean = mean_x, sigma = sigma)
y      = rmvnorm(n=n, mean = mean_y, sigma = sigma)
xy     = rbind(x,y) # defined for computing xlim and ylim
plot(x, col='red', pch = 19, ylim = c(round(min(xy[,2]))-1,round(max(xy[,2]))+1),
xlim = c(round(min(xy[,1]))-1,round(max(xy[,1]))+1),
xlab = 'x1, y1', ylab = 'x2, y2')
points(y,col = 'blue', pch = 19)
